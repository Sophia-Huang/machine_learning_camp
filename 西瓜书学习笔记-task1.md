# 绪论

## 机器学习的定义

机器学习致力于从历史的经验（数据）中学习到一些规律（算法），从而对未来的情况给出一定的决策建议（预测）。

> [Mitchell, 1997] 给出了一个更形式化的定义：假设用P来评估计算机程序在某任务类T上的性能，若一个程序通过利用经验E在T中任务上获得了性能改善，则我们就说关于T和P，该程序对E进行了学习。

## 机器学习的基本术语

- 数据集：所有记录的集合
- 实例（instance）/ 样本（sample）：每一条记录
- 特征（feature）/ 属性（attribute）：每一个实例的特点
- 特征向量（feature vector）：将每一条记录在坐标轴上表示，每个实例用坐标轴的一个点表示，则所有特征组成的向量就是特征向量

- 维数（dimensionality）：样本的特征数

- 训练样本（training sample）：计算机程序学习经验数据生成算法模型的过程中的每一条历史记录
- 测试样本（testing sample）：用于测试模型效果的新样本
- 训练集（training set）：所有训练样本的集合[特殊]
- 测试集（testing set）：所有测试样本的集合[一般]
- 泛化能力（generalization）：机器学习出来的模型适用于新样本的能力

- 分类（classification）：预测值为离散值的问题
- 回归（regression）：预测值为连续值的问题
- 监督学习（supervised learning）：训练数据有标记信息的学习任务，分类和回归都是监督学习。
- 无监督学习（unsupervised learning）：训练数据没有标记信息的学习任务，常见的无监督学习有聚类、关联规则等。

# 模型的评估与选择

## 经验误差与过拟合

定义：

- 误差（error）：学习器对于样本的预测结果与样本真实结果之间的差异
- 训练误差（train error）/ 经验误差（empirical error）：训练集上的误差
- 测试误差（test error）：测试集上的误差
- 泛化误差（generalization error）：模型在所有新样本上的误差
- 过拟合（overfit）：学习能力太强，学到了训练集样本的特殊性
- 欠拟合（underfit）：学习能力太弱，没有学到训练集样本的一般性

## 评估方法

为了体现模型的泛化性能，测试集应该尽可能与训练集互斥。

常用的划分训练集与测试集的方法有：

- 留出法（hold-out）：直接将数据集划分为两个互斥的集合，也即留出一部分数据作为测试集
- 交叉验证法（cross validation）：先将数据集划分成k个大小相似的互斥子集，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集
- 自助法（bootstrap）：对大小为n的数据集进行n次有放回抽样，新的训练集，再将原数据集中没有被采样过的样本并集作为测试集。从极限来说，测试集样本约有36.8%。

## 性能度量

### 回归任务

- MSE均方误差：$\text{MSE}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} (y_i - \hat{y}_i)^2.$
- MAE平均绝对误差:$\text{MAE}(y, \hat{y}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}}-1} \left| y_i - \hat{y}_i \right|$
- $R^2$决定系数：$R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}$
- 解释方差得分:$explained\_{}variance(y, \hat{y}) = 1 - \frac{Var\{ y - \hat{y}\}}{Var\{y\}}$

### 分类任务

   - 真阳性TP：预测值和真实值都为正例；                        
   - 真阴性TN：预测值与真实值都为正例；                     
   - 假阳性FP：预测值为正，实际值为负；
   - 假阴性FN：预测值为负，实际值为正；     
   - 混淆矩阵：TP/TN/FP/FN的矩阵                                                                  
   - 准确率：分类正确的样本数占总样本的比例，即：$ACC = \frac{TP+TN}{FP+FN+TP+TN}$.                                
   - 精确率（查准率）：预测为正且分类正确的样本占预测值为正的比例，即：$PRE = \frac{TP}{TP+FP}$.                     
   - 召回率（查全率）：预测为正且分类正确的样本占类别为正的比例，即：$REC =  \frac{TP}{TP+FN}$.                     
   - F1值：综合衡量精度和召回率，即：$F1 = 2\frac{PRE\times REC}{PRE + REC}$.       
   - PR图：查准率-查全率曲线                              
   - ROC曲线：以假阳率为横轴，真阳率为纵轴画出来的曲线
   - AUC：ROC曲线下方的面积，越大越好
   - 代价敏感错误率：对不同类型错误赋予不同的损失权重，对错误率加权求和